import os
import numpy as np
from collections import defaultdict
from datetime import datetime
import json

class SummaryCollector:
    def __init__(self):
        self.total_frames = 0
        self.activity_counts = defaultdict(int)
        self.emotion_counts = defaultdict(int)
        self.emotion_per_frame = []
        self.face_sizes = []
        self.detection_confidences = []
        self.detection_methods = defaultdict(int)
        self.frame_face_counts = []  # N√∫mero de rostos por frame
        self.emotion_transitions = defaultdict(int)
        self.last_emotion_per_face = {}
        
        # Novas m√©tricas
        self.emotion_durations = defaultdict(list)
        self.current_emotion_start = {}
        self.face_qualities = []
        self.temporal_analysis = []

    def update(self, frame_index, faces_info, activity_label):
        """Atualiza estat√≠sticas com informa√ß√µes do frame atual"""
        self.total_frames = frame_index
        self.activity_counts[activity_label] += 1
        
        # Contar emo√ß√µes
        face_count = len(faces_info)
        self.frame_face_counts.append(face_count)
        
        for i, face_info in enumerate(faces_info):
            emotion = face_info.get("emotion", "desconhecido")
            self.emotion_counts[emotion] += 1
            
            # Rastrear dura√ß√£o das emo√ß√µes por rosto
            face_id = i  # Simplificado - em produ√ß√£o usar tracking ID
            if face_id not in self.current_emotion_start:
                self.current_emotion_start[face_id] = (emotion, frame_index)
            else:
                last_emotion, start_frame = self.current_emotion_start[face_id]
                if last_emotion != emotion:
                    # Registra dura√ß√£o da emo√ß√£o anterior
                    duration = frame_index - start_frame
                    self.emotion_durations[last_emotion].append(duration)
                    self.emotion_transitions[f"{last_emotion}->{emotion}"] += 1
                    self.current_emotion_start[face_id] = (emotion, frame_index)
            
            # Coletar m√©tricas de qualidade
            if "detection_confidence" in face_info:
                self.detection_confidences.append(face_info["detection_confidence"])
            
            if "detection_method" in face_info:
                self.detection_methods[face_info["detection_method"]] += 1
            
            if "face_area" in face_info:
                self.face_sizes.append(face_info["face_area"])
                
                # Calcular qualidade baseada em tamanho e confian√ßa
                area = face_info["face_area"]
                conf = face_info.get("detection_confidence", 0.5)
                quality = min(1.0, (area / 10000) * conf)  # Normalizado
                self.face_qualities.append(quality)
        
        # An√°lise temporal (amostrar a cada 30 frames)
        if frame_index % 30 == 0:
            self.temporal_analysis.append({
                "frame": frame_index,
                "face_count": face_count,
                "emotions": [f.get("emotion", "desconhecido") for f in faces_info],
                "timestamp": datetime.now().strftime("%H:%M:%S")
            })

    def calculate_metrics(self):
        """Calcula m√©tricas de qualidade"""
        metrics = {}
        
        # Taxa de detec√ß√£o
        frames_with_faces = sum(1 for count in self.frame_face_counts if count > 0)
        metrics["face_detection_rate"] = frames_with_faces / max(1, self.total_frames) if self.total_frames > 0 else 0
        
        # M√©dia de rostos por frame
        metrics["avg_faces_per_frame"] = np.mean(self.frame_face_counts) if self.frame_face_counts else 0
        
        # Qualidade de detec√ß√£o
        metrics["avg_detection_confidence"] = np.mean(self.detection_confidences) if self.detection_confidences else 0
        metrics["avg_face_quality"] = np.mean(self.face_qualities) if self.face_qualities else 0
        
        # Distribui√ß√£o de tamanhos
        if self.face_sizes:
            metrics["avg_face_size"] = np.mean(self.face_sizes)
            metrics["min_face_size"] = np.min(self.face_sizes)
            metrics["max_face_size"] = np.max(self.face_sizes)
        else:
            metrics["avg_face_size"] = 0
            metrics["min_face_size"] = 0
            metrics["max_face_size"] = 0
        
        # Dura√ß√£o m√©dia das emo√ß√µes
        metrics["avg_emotion_duration"] = {}
        for emotion, durations in self.emotion_durations.items():
            if durations:
                metrics["avg_emotion_duration"][emotion] = np.mean(durations)
        
        # Estabilidade emocional (menos transi√ß√µes = mais est√°vel)
        total_faces = sum(self.emotion_counts.values())
        total_transitions = sum(self.emotion_transitions.values())
        metrics["emotional_stability"] = 1 - (total_transitions / max(1, total_faces)) if total_faces > 0 else 0
        
        # M√©todos de detec√ß√£o usados
        metrics["detection_method_distribution"] = dict(self.detection_methods)
        
        return metrics

    def export(self, output_path="outputs/resumo_automatico.txt"):
        """Exporta o resumo com m√©tricas de qualidade"""
        # Garantir que o diret√≥rio existe
        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # Calcular m√©tricas
        quality_metrics = self.calculate_metrics()
        
        with open(output_path, "w", encoding="utf-8") as f:
            f.write("=" * 60 + "\n")
            f.write("RESUMO AUTOM√ÅTICO DA AN√ÅLISE DE V√çDEO\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("üìä INFORMA√á√ïES GERAIS\n")
            f.write("-" * 40 + "\n")
            f.write(f"Total de frames analisados: {self.total_frames}\n")
            f.write(f"Data/hora da an√°lise: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n\n")
            
            f.write("üéØ M√âTRICAS DE QUALIDADE DA DETEC√á√ÉO\n")
            f.write("-" * 40 + "\n")
            f.write(f"Taxa de detec√ß√£o facial: {quality_metrics['face_detection_rate']:.1%}\n")
            f.write(f"M√©dia de rostos por frame: {quality_metrics['avg_faces_per_frame']:.2f}\n")
            f.write(f"Confian√ßa m√©dia de detec√ß√£o: {quality_metrics['avg_detection_confidence']:.2f}/1.0\n")
            f.write(f"Qualidade m√©dia dos rostos: {quality_metrics['avg_face_quality']:.2f}/1.0\n")
            
            if quality_metrics['avg_face_size'] > 0:
                f.write(f"Tamanho m√©dio dos rostos: {quality_metrics['avg_face_size']:.0f} pixels\n")
                f.write(f"Tamanho m√≠nimo: {quality_metrics['min_face_size']:.0f} pixels\n")
                f.write(f"Tamanho m√°ximo: {quality_metrics['max_face_size']:.0f} pixels\n")
            else:
                f.write("Informa√ß√µes de tamanho dos rostos n√£o dispon√≠veis\n")
            
            f.write(f"Estabilidade emocional: {quality_metrics['emotional_stability']:.1%}\n\n")
            
            f.write("üîÑ DISTRIBUI√á√ÉO DOS M√âTODOS DE DETEC√á√ÉO\n")
            f.write("-" * 40 + "\n")
            detection_methods = quality_metrics.get('detection_method_distribution', {})
            if detection_methods:
                total_detections = sum(detection_methods.values())
                for method, count in detection_methods.items():
                    percentage = count / total_detections * 100 if total_detections > 0 else 0
                    f.write(f"- {method}: {count} detec√ß√µes ({percentage:.1f}%)\n")
            else:
                f.write("Informa√ß√µes de m√©todos de detec√ß√£o n√£o dispon√≠veis\n")
            f.write("\n")
            
            f.write("üö∂ ATIVIDADES MAIS FREQUENTES\n")
            f.write("-" * 40 + "\n")
            if self.activity_counts:
                sorted_activities = sorted(self.activity_counts.items(), 
                                          key=lambda x: x[1], reverse=True)
                for activity, count in sorted_activities:
                    percentage = count / self.total_frames * 100 if self.total_frames > 0 else 0
                    f.write(f"- {activity}: {count} frames ({percentage:.1f}%)\n")
            else:
                f.write("Nenhuma atividade registrada\n")
            f.write("\n")
            
            f.write("üòä EMO√á√ïES MAIS FREQUENTES\n")
            f.write("-" * 40 + "\n")
            total_faces = sum(self.emotion_counts.values())
            if total_faces > 0:
                sorted_emotions = sorted(self.emotion_counts.items(), 
                                        key=lambda x: x[1], reverse=True)
                
                for emotion, count in sorted_emotions:
                    percentage = count / total_faces * 100
                    
                    # Adicionar dura√ß√£o m√©dia se dispon√≠vel
                    duration_info = ""
                    if emotion in quality_metrics['avg_emotion_duration']:
                        avg_dur = quality_metrics['avg_emotion_duration'][emotion]
                        duration_info = f" (dura {avg_dur:.1f} frames em m√©dia)"
                    
                    f.write(f"- {emotion}: {count} rostos detectados ({percentage:.1f}%){duration_info}\n")
            else:
                f.write("Nenhuma emo√ß√£o detectada\n")
            f.write("\n")
            
            f.write("üîÑ PRINCIPAIS TRANSI√á√ïES EMOCIONAIS\n")
            f.write("-" * 40 + "\n")
            if self.emotion_transitions:
                sorted_transitions = sorted(self.emotion_transitions.items(), 
                                          key=lambda x: x[1], reverse=True)[:10]  # Top 10
                for transition, count in sorted_transitions:
                    f.write(f"- {transition}: {count} vezes\n")
            else:
                f.write("Nenhuma transi√ß√£o significativa detectada.\n")
            f.write("\n")
            
            f.write("üìà AN√ÅLISE TEMPORAL (amostras)\n")
            f.write("-" * 40 + "\n")
            if self.temporal_analysis:
                for sample in self.temporal_analysis[:5]:  # Mostrar primeiras 5 amostras
                    f.write(f"Frame {sample['frame']} ({sample['timestamp']}): ")
                    f.write(f"{sample['face_count']} rosto(s) - ")
                    f.write(f"Emo√ß√µes: {', '.join(sample['emotions'])}\n")
            else:
                f.write("An√°lise temporal n√£o dispon√≠vel\n")
            f.write("\n")
            
            f.write("üí° RECOMENDA√á√ïES T√âCNICAS\n")
            f.write("-" * 40 + "\n")
            
            # An√°lise autom√°tica baseada nas m√©tricas
            recommendations = []
            
            if quality_metrics['face_detection_rate'] < 0.3:
                recommendations.append("‚ö†Ô∏è  Taxa de detec√ß√£o baixa. Verifique:")
                recommendations.append("   ‚Ä¢ Ilumina√ß√£o do ambiente")
                recommendations.append("   ‚Ä¢ Posicionamento da c√¢mera")
                recommendations.append("   ‚Ä¢ Oclus√£o dos rostos")
            
            if quality_metrics['avg_detection_confidence'] < 0.4:
                recommendations.append("‚ö†Ô∏è  Confian√ßa de detec√ß√£o abaixo do ideal.")
                recommendations.append("   ‚Ä¢ Considere ajustar os limiares de detec√ß√£o")
                recommendations.append("   ‚Ä¢ Melhorar a qualidade do v√≠deo")
            
            if quality_metrics['emotional_stability'] < 0.5:
                recommendations.append("‚ö†Ô∏è  Baixa estabilidade emocional detectada.")
                recommendations.append("   ‚Ä¢ Pode indicar mudan√ßas r√°pidas de express√£o")
                recommendations.append("   ‚Ä¢ Ou instabilidade na detec√ß√£o")
            
            if quality_metrics.get('avg_face_size', 0) < 2000 and quality_metrics['avg_face_size'] > 0:
                recommendations.append("‚ö†Ô∏è  Rostos muito pequenos na imagem.")
                recommendations.append("   ‚Ä¢ Aproxime a c√¢mera dos sujeitos")
                recommendations.append("   ‚Ä¢ Use zoom digital se dispon√≠vel")
            
            if recommendations:
                for rec in recommendations:
                    f.write(rec + "\n")
            else:
                f.write("‚úÖ Todas as m√©tricas est√£o dentro dos par√¢metros ideais\n")
            
            f.write("\n‚úÖ CONFIGURA√á√ÉO IDEAL:\n")
            f.write("   ‚Ä¢ Taxa de detec√ß√£o: > 70%\n")
            f.write("   ‚Ä¢ Confian√ßa m√©dia: > 0.6\n")
            f.write("   ‚Ä¢ Tamanho do rosto: > 4000 pixels\n")
            f.write("   ‚Ä¢ Estabilidade emocional: > 60%\n")
            
            f.write("\n" + "=" * 60 + "\n")
            f.write("FIM DO RELAT√ìRIO\n")
            f.write("=" * 60 + "\n")
        
        print(f"Resumo salvo em: {output_path}")
        
        # Tamb√©m salvar como JSON para an√°lise posterior
        json_path = output_path.replace(".txt", "_detalhado.json")
        detailed_data = {
            "geral": {
                "total_frames": self.total_frames,
                "timestamp": datetime.now().isoformat()
            },
            "atividades": dict(self.activity_counts),
            "emocoes": dict(self.emotion_counts),
            "metricas_qualidade": quality_metrics,
            "transicoes": dict(self.emotion_transitions),
            "analise_temporal": self.temporal_analysis
        }
        
        try:
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(detailed_data, f, indent=2, ensure_ascii=False)
            print(f"Relat√≥rio detalhado (JSON) salvo em: {json_path}")
        except Exception as e:
            print(f"Erro ao salvar JSON: {e}")