# Tech Challenge 4 - An√°lise de V√≠deo com IA

Sistema de an√°lise de v√≠deo que utiliza vis√£o computacional e processamento de imagens para detectar rostos, classificar emo√ß√µes faciais e identificar atividades em v√≠deos.

## Descri√ß√£o

Este projeto implementa uma solu√ß√£o completa de an√°lise de v√≠deo que combina m√∫ltiplas t√©cnicas de vis√£o computacional para:

- **Detec√ß√£o Facial**: Identifica rostos em cada frame usando MediaPipe Face Detection e Haar Cascade (como fallback)
- **Classifica√ß√£o de Emo√ß√µes**: Analisa express√µes faciais e classifica emo√ß√µes como alegre, triste, surpreso, pensativo, entre outras
- **Detec√ß√£o de Atividades**: Monitora o movimento global do v√≠deo e classifica em n√≠veis de atividade (parado, movimento leve, moderado, intenso)
- **Gera√ß√£o de Resumo**: Cria relat√≥rios autom√°ticos com estat√≠sticas detalhadas e m√©tricas de qualidade

## Funcionalidades

### 1. Detec√ß√£o Facial
- Utiliza **MediaPipe Face Detection** como m√©todo principal
- Fallback autom√°tico para **Haar Cascade** quando necess√°rio
- Suporta detec√ß√£o de m√∫ltiplos rostos por frame
- Detecta rostos frontais e de lado
- Calcula confian√ßa de detec√ß√£o para cada rosto identificado

### 2. Classifica√ß√£o de Emo√ß√µes
O sistema identifica as seguintes emo√ß√µes:
- **Alegre/Sorridente**: Boca aberta com intensidade alta
- **Triste**: Boca fechada com intensidade baixa
- **Surpreso**: Boca e olhos muito abertos
- **Pensativo**: Olhos baixos, boca fechada, pouca varia√ß√£o
- **Desd√©m**: Sobrancelhas assim√©tricas, boca fechada
- **Careta**: Assimetria significativa da boca
- **Ang√∫stia**: Boca parcialmente aberta, intensidade m√©dia
- **Neutro**: Express√£o padr√£o
- **Rosto de Lado**: Quando o rosto n√£o est√° frontal

### 3. Detec√ß√£o de Atividades
Classifica o movimento global do v√≠deo em:
- **Parado**: Pouco ou nenhum movimento (< 3)
- **Movimento Leve**: Movimento sutil (3-8)
- **Movimento Moderado**: Movimento m√©dio (8-20)
- **Movimento Intenso**: Movimento significativo (> 20)

### 4. Gera√ß√£o de Relat√≥rios
O sistema gera dois tipos de relat√≥rios:
- **Relat√≥rio em Texto** (`resumo_automatico.txt`): Resumo leg√≠vel com estat√≠sticas
- **Relat√≥rio JSON** (`resumo_automatico_detalhado.json`): Dados estruturados para an√°lise posterior

## Depend√™ncias

O projeto utiliza as seguintes bibliotecas Python:

- `numpy==1.24.3` - Opera√ß√µes num√©ricas e arrays
- `opencv-python==4.8.1.78` - Processamento de imagens e v√≠deo
- `mediapipe==0.10.7` - Detec√ß√£o facial e an√°lise de landmarks
- `protobuf==3.20.3` - Serializa√ß√£o de dados (requerido pelo MediaPipe)

## Instala√ß√£o

1. Clone o reposit√≥rio ou navegue at√© o diret√≥rio do projeto
2. Crie um ambiente virtual (recomendado)
3. Instale as depend√™ncias descritas em requirements.txt

## Estrutura do Projeto

```
tech_challenge_4_pos_tech_ia/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # Script principal de execu√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ face_emotion.py         # M√≥dulo de detec√ß√£o facial e emo√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ activity_detection.py   # M√≥dulo de detec√ß√£o de atividades
‚îÇ   ‚îú‚îÄ‚îÄ summary.py              # M√≥dulo de gera√ß√£o de resumos
‚îÇ   ‚îú‚îÄ‚îÄ haarcascade_frontalface_default.xml  # Classificador Haar Cascade
‚îÇ   ‚îî‚îÄ‚îÄ haarcascade_smile.xml   # Classificador adicional
‚îú‚îÄ‚îÄ outputs/                    # Diret√≥rio de sa√≠da (criado automaticamente)
‚îÇ   ‚îú‚îÄ‚îÄ annotated_video.mp4     # V√≠deo processado com anota√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ resumo_automatico.txt   # Relat√≥rio em texto
‚îÇ   ‚îî‚îÄ‚îÄ resumo_automatico_detalhado.json  # Relat√≥rio JSON
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ video_tech.mp4              # V√≠deo de exemplo (se dispon√≠vel)
‚îî‚îÄ‚îÄ README.md                   # Este arquivo
```

## Como Usar

### Execu√ß√£o B√°sica

Execute o script principal com o caminho do v√≠deo:

```bash
python src/main.py --video_path video_tech.mp4
```

### Par√¢metros

- `--video_path`: Caminho para o arquivo de v√≠deo a ser processado (padr√£o: `video_tech.mp4`)

### Exemplo

```bash
python src/main.py --video_path meu_video.mp4
```

## Sa√≠das do Sistema

Ap√≥s o processamento, o sistema gera:

1. **V√≠deo Anotado** (`outputs/annotated_video.mp4`):
   - V√≠deo com bounding boxes coloridos ao redor dos rostos
   - Labels de emo√ß√£o para cada rosto detectado
   - Informa√ß√µes de atividade no canto superior
   - Informa√ß√µes de debug (abertura da boca, olhos, etc.)

2. **Relat√≥rio de Resumo** (`outputs/resumo_automatico.txt`):
   - Estat√≠sticas gerais (total de frames, data/hora)
   - M√©tricas de qualidade da detec√ß√£o
   - Distribui√ß√£o de atividades
   - Distribui√ß√£o de emo√ß√µes
   - Transi√ß√µes emocionais mais frequentes
   - An√°lise temporal
   - Recomenda√ß√µes t√©cnicas

3. **Relat√≥rio JSON** (`outputs/resumo_automatico_detalhado.json`):
   - Dados estruturados para an√°lise program√°tica
   - Todas as m√©tricas em formato JSON

## M√©tricas de Qualidade

O sistema calcula e reporta:

- **Taxa de Detec√ß√£o Facial**: Percentual de frames com rostos detectados
- **Confian√ßa M√©dia de Detec√ß√£o**: Confian√ßa m√©dia das detec√ß√µes
- **Qualidade M√©dia dos Rostos**: M√©trica combinada de tamanho e confian√ßa
- **Estabilidade Emocional**: Medida de consist√™ncia das emo√ß√µes detectadas
- **Distribui√ß√£o de M√©todos**: Uso de MediaPipe vs Haar Cascade
- **Dura√ß√£o M√©dia das Emo√ß√µes**: Tempo m√©dio que cada emo√ß√£o persiste

## Cores das Anota√ß√µes

Cada emo√ß√£o √© representada por uma cor espec√≠fica no v√≠deo anotado:

- üîµ Azul: Surpreso
- üü¢ Verde: Alegre/Sorridente/Neutro
- üü° Amarelo: Careta/Pensativo
- üü£ Magenta: Triste
- üü† Laranja: Desd√©m
- üü£ Roxo: Ang√∫stia
- ‚ö™ Cinza: Rosto de Lado

## Detalhes T√©cnicos

### Detec√ß√£o Facial

O sistema utiliza uma abordagem h√≠brida:
1. **MediaPipe Face Detection**: M√©todo principal, mais preciso e r√°pido
2. **Haar Cascade**: Fallback quando MediaPipe n√£o detecta rostos
3. **MediaPipe Face Mesh**: Para an√°lise detalhada de landmarks faciais

### Classifica√ß√£o de Emo√ß√µes

A classifica√ß√£o utiliza m√∫ltiplas m√©tricas:
- Abertura da boca (dist√¢ncia entre l√°bios)
- Abertura dos olhos
- Posi√ß√£o das sobrancelhas
- Assimetria facial
- Intensidade m√©dia e desvio padr√£o da imagem
- Orienta√ß√£o do rosto (frontal vs lateral)

### Detec√ß√£o de Atividades

Baseada na diferen√ßa absoluta entre frames consecutivos:
- Converte frames para escala de cinza
- Calcula diferen√ßa pixel a pixel
- Classifica baseado em limiares emp√≠ricos

## Estat√≠sticas Reportadas

O sistema fornece estat√≠sticas detalhadas incluindo:

- Total de frames processados
- Frames com/sem rostos detectados
- Taxa de detec√ß√£o facial
- Total de rostos detectados
- Distribui√ß√£o de m√©todos de detec√ß√£o (MediaPipe vs Haar)
- Mudan√ßas de emo√ß√£o detectadas
- Atividades mais frequentes
- Emo√ß√µes mais frequentes
- Principais transi√ß√µes emocionais
- An√°lise temporal (amostras)

## Configura√ß√£o e Ajustes

### Ajustar Limiares de Atividade

Edite `src/activity_detection.py` para modificar os limiares:
```python
if motion_value < 3:
    activity = "parado"
elif motion_value < 8:
    activity = "movimento leve"
# ... etc
```

### Ajustar Sensibilidade de Emo√ß√µes

Edite `src/face_emotion.py` na fun√ß√£o `classify_emotion_with_mesh()` para modificar os limiares de classifica√ß√£o.

### Configurar MediaPipe

Ajuste os par√¢metros de detec√ß√£o em `src/face_emotion.py`:
```python
face_detector = mp_face_detection.FaceDetection(
    model_selection=0,  # 0 = curto alcance, 1 = longo alcance
    min_detection_confidence=0.5  # Limiar de confian√ßa
)
```

## üìÑ Licen√ßa

Este projeto foi desenvolvido para o Tech Challenge 4 - P√≥s-Tech IA.

