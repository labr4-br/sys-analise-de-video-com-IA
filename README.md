# Tech Challenge 4 - Sistema de An√°lise de V√≠deo com IA

Sistema inteligente de an√°lise de v√≠deo que detecta faces, identifica emo√ß√µes e classifica atividades em tempo real usando t√©cnicas avan√ßadas de vis√£o computacional e aprendizado de m√°quina.

## Funcionalidades

- **Detec√ß√£o de Faces**: Utiliza MediaPipe e YOLO como fallback para garantir melhor precis√£o
- **Reconhecimento de Emo√ß√µes**: An√°lise de express√µes faciais com a biblioteca FER (Facial Emotion Recognition)
- **Classifica√ß√£o de Atividades**: Detecta n√≠veis de movimento no v√≠deo (parado, leve, moderado, intenso)
- **Gera√ß√£o de Relat√≥rios**: Exporta resumo estat√≠stico completo da an√°lise
- **Processamento em Lote**: Processa v√≠deos completos com barra de progresso

## Arquitetura do Sistema

O projeto est√° organizado em m√≥dulos especializados:

```
tech_challenge_4/
‚îú‚îÄ‚îÄ main.py                      # Script principal de execu√ß√£o
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ face_detection.py        # Detec√ß√£o de faces (MediaPipe + YOLO)
‚îÇ   ‚îú‚îÄ‚îÄ emotion_detection.py     # An√°lise de emo√ß√µes (FER)
‚îÇ   ‚îú‚îÄ‚îÄ activity_detection.py    # Classifica√ß√£o de atividades
‚îÇ   ‚îî‚îÄ‚îÄ summary.py               # Gera√ß√£o de relat√≥rios
‚îú‚îÄ‚îÄ requirements.txt             # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md                    # Documenta√ß√£o
```

### Fluxo de Processamento

1. **Captura de V√≠deo**: Leitura frame a frame do v√≠deo de entrada
2. **Detec√ß√£o de Faces**: 
   - Primeira tentativa com MediaPipe (otimizado e r√°pido)
   - Fallback para YOLO se MediaPipe n√£o detectar faces
3. **An√°lise de Emo√ß√µes**: FER analisa cada face detectada
4. **Detec√ß√£o de Atividade**: An√°lise de movimento entre frames consecutivos
5. **Anota√ß√£o Visual**: Desenha ret√¢ngulos e labels no frame
6. **Coleta de Estat√≠sticas**: Acumula dados para o relat√≥rio final
7. **Exporta√ß√£o**: Salva v√≠deo processado e relat√≥rio em texto

## Instala√ß√£o

### Pr√©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)
- Arquivo de v√≠deo para an√°lise

### Passos de Instala√ß√£o

1. **Clone o reposit√≥rio**:
```bash
git clone <url-do-repositorio>
cd tech_challenge_4
```

2. **Crie um ambiente virtual**:
```bash
python -m venv venv
source venv/bin/activate
```

3. **Instale as depend√™ncias**:
```bash
pip install -r requirements.txt
```

4. **Baixe os modelos necess√°rios**:
   - **MediaPipe**: Baixe `blaze_face_short_range.tflite` e coloque na raiz do projeto
   - **YOLO**: O modelo `yolo11n.pt` ser√° baixado automaticamente na primeira execu√ß√£o

## Como Usar

### Uso B√°sico

Execute o script principal com um v√≠deo de entrada:

```bash
python main.py
```

Por padr√£o, o script processa `video_tech.mp4` e gera:
- `output_mediapipe_yolo.mp4` - V√≠deo com anota√ß√µes visuais
- `output_mediapipe_yolo_summary.txt` - Relat√≥rio estat√≠stico

### Personaliza√ß√£o

Edite o arquivo `main.py` para alterar os caminhos:

```python
if __name__ == "__main__":
    main('seu_video.mp4', 'saida_processada.mp4')
```

### Ajuste de Par√¢metros

#### Detec√ß√£o de Faces (MediaPipe)

```python
# Em src/face_detection.py
min_detection_confidence=0.6,  # Confian√ßa m√≠nima (0.0 a 1.0)
min_suppression_threshold=0.3   # Supress√£o de detec√ß√µes pr√≥ximas
```

#### Detec√ß√£o de Faces (YOLO)

```python
# Em main.py
yolo_face_detection = YOLOFaceDetection(confidence_threshold=0.4)
```

#### Classifica√ß√£o de Atividades

```python
# Em src/activity_detection.py
# Ajuste os limiares de movimento:
if motion_value < 3:
    activity = "parado"
elif motion_value < 8:
    activity = "movimento leve"
elif motion_value < 20:
    activity = "movimento moderado"
else:
    activity = "movimento intenso"
```

## Formato do Relat√≥rio

O arquivo de resumo gerado cont√©m:

```
============================================================
RESUMO AUTOM√ÅTICO DA AN√ÅLISE DE V√çDEO
============================================================

Total de frames analisados: 1500

------------------------------------------------------------
ATIVIDADES DETECTADAS
------------------------------------------------------------
  ‚Ä¢ Movimento leve: 850 frames (56.7%)
  ‚Ä¢ Parado: 450 frames (30.0%)
  ‚Ä¢ Movimento moderado: 200 frames (13.3%)

------------------------------------------------------------
EMO√á√ïES DETECTADAS
------------------------------------------------------------
  ‚Ä¢ Happy: 450 detec√ß√µes (45.0%)
  ‚Ä¢ Neutral: 300 detec√ß√µes (30.0%)
  ‚Ä¢ Surprise: 150 detec√ß√µes (15.0%)
  ‚Ä¢ Sad: 100 detec√ß√µes (10.0%)

============================================================
```

## Tecnologias Utilizadas

### Bibliotecas Principais

- **OpenCV** (4.10.0.84): Processamento de imagens e v√≠deo
- **MediaPipe** (0.10.21): Detec√ß√£o de faces em tempo real
- **Ultralytics YOLO** (8.3.239): Detec√ß√£o de objetos e faces (fallback)
- **FER** (22.5.1): Reconhecimento de emo√ß√µes faciais
- **TensorFlow** (2.17.1): Backend para modelos de deep learning
- **PyTorch** (2.2.2): Framework de deep learning
- **NumPy** (1.26.4): Computa√ß√£o num√©rica
- **tqdm** (4.67.1): Barras de progresso

### Modelos de IA

1. **BlazeFace** (MediaPipe): Detector de faces leve e r√°pido
2. **YOLO11n**: Detector de objetos de √∫ltima gera√ß√£o
3. **FER**: Rede neural para classifica√ß√£o de emo√ß√µes

## Detalhes T√©cnicos

### Detec√ß√£o de Faces H√≠brida

O sistema implementa uma estrat√©gia de fallback inteligente:

```python
# Tenta primeiro com MediaPipe (mais r√°pido)
faces = media_pipe_face_detection.face_detection(frame, fps)

# Se falhar, usa YOLO (mais robusto)
if not faces:
    faces = yolo_face_detection.face_detection(frame)
```

### Pr√©-processamento de Imagens

Para melhorar a detec√ß√£o, o sistema aplica equaliza√ß√£o de histograma:

```python
frame_yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)
frame_yuv[:,:,0] = cv2.equalizeHist(frame_yuv[:,:,0])
enhanced_frame = cv2.cvtColor(frame_yuv, cv2.COLOR_YUV2BGR)
```

### Detec√ß√£o de Atividades

Usa diferen√ßa absoluta entre frames consecutivos:

```python
diff = cv2.absdiff(gray, prev_gray)
motion_value = float(np.mean(diff))
```

### An√°lise de Emo√ß√µes

Adiciona margem de 20% ao redor das faces para melhor contexto:

```python
margin = 0.2
x_margin = int(w * margin)
y_margin = int(h * margin)
```

## üé® Visualiza√ß√£o

O v√≠deo de sa√≠da inclui:

- **Ret√¢ngulos verdes**: Faces detectadas
- **Labels de emo√ß√£o**: Tipo e confian√ßa (em magenta)
- **Indicador de atividade**: N√≠vel de movimento (em laranja)

## Solu√ß√£o de Problemas

### GPU Desabilitada

O sistema desabilita GPU por padr√£o para evitar problemas de compatibilidade:

```python
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
```

Para habilitar GPU, comente ou remova esta linha em `main.py`.

### Erro ao Carregar Modelos

Certifique-se de que:
- `blaze_face_short_range.tflite` est√° na raiz do projeto
- Voc√™ tem conex√£o com internet para baixar o YOLO na primeira execu√ß√£o

### Baixa Taxa de Detec√ß√£o

Tente:
- Reduzir `min_detection_confidence` no MediaPipe
- Reduzir `confidence_threshold` no YOLO
- Melhorar a ilumina√ß√£o do v√≠deo de entrada

### Consumo Alto de Mem√≥ria

Para v√≠deos muito longos:
- Processe em lotes menores
- Reduza a resolu√ß√£o do v√≠deo de entrada
- Use um modelo YOLO menor (yolo11n.pt)

## Performance

### Benchmarks T√≠picos

- **Velocidade**: ~15-30 FPS em CPU moderna
- **Precis√£o de Detec√ß√£o**: >90% em condi√ß√µes ideais
- **Uso de Mem√≥ria**: ~2-4 GB RAM

### Otimiza√ß√µes Implementadas

- Inicializa√ß√£o √∫nica dos detectores
- Processamento vetorizado com NumPy
- Fallback inteligente entre modelos
- Desabilita√ß√£o de verbose nos modelos

## Licen√ßa

Este projeto √© de c√≥digo aberto e est√° dispon√≠vel para uso educacional e comercial.

## Autores

- Bruna Ballerini

---

**Nota**: Este projeto foi desenvolvido como parte do Tech Challenge 4 e demonstra a integra√ß√£o de m√∫ltiplas tecnologias de IA para an√°lise de v√≠deo em tempo real.
